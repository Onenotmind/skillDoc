# 简单线性回归

假设我们找到了最佳拟合的直线方程
$$y = ax + b $$

对于每一个样本 $x^{(i)}$
根据我们的直线方程，预测值为：

$$\hat{y}^{(i)} = ax^{(i)} + b$$

真值为： $y^{(i)}$

表达$y^{(i)}$ 与$\hat{y}^{(i)}$的差距：

$$(y^{(i)} - \hat{y}^{(i)})^{2} $$

所有样本的差距：
$$\sum_{i=1}^m(y^{(i)} - \hat{y}^{(i)})^{2}$$

将$\hat{y}^{(i)} = ax^{(i)} + b$代入，得到损失函数如下：
$$\sum_{i=1}^m(y^{(i)} - ax^{(i)} - b)^{2}$$

如何找到a,b, 使得损失函数最小呢？

# 最小二乘法

对b进行偏导数。
$$J(a, b) = \sum_{i=1}^m(y^{(i)} - ax^{(i)} - b)^{2}$$

$$\frac{dJ(a, b)}{db} = \sum_{i=1}^m2(y^{(i)} - ax^{(i)} - b)(-1) = 0$$

$$\sum_{i=1}^m(y^{(i)} - ax^{(i)} - b) = 0$$

$$\sum_{i=1}^my^{(i)} - a\sum_{i=1}^mx^{(i)} - \sum_{i=1}^mb = 0$$

$$\sum_{i=1}^my^{(i)} - a\sum_{i=1}^mx^{(i)} - mb = 0$$

$$mb = \sum_{i=1}^my^{(i)} - a\sum_{i=1}^mx^{(i)} = 0$$

$$b = \bar{y} - a\bar{x}$$

同理可得：

$$a = $$

# 简单线性回归


# 向量化（数学表达式的优化）

# 线性回归算法的评测

> 均方根误差 RMSE(Root Mean Squared Error)

$$\sqrt{\frac{1}{m}\sum_{i=1}^{m}(y_{test}^{(i)} - \hat{y}_{test}^{(i)})^{2}}$$

> 平均绝对误差 MAE(Mean Absolute Error)

$$\frac{1}{m}\sum_{i=1}^{m}|y_{test}^{(i)} - \hat{y}_{test}^{(i)}|$$

# R Squared（线性关系衡量）

$$R^2 = 1 - \frac{\sum_{i}(\hat{y}^{(i)} - y^{(i)})^{2}}{\sum_{i}(\bar{y}^{(i)} - y^{(i)})^{2}}$$

当 $R^2 <= 1$ 时， $R^2$ 越大越好.

当$R^2 == 0$ 训练模型等于基准模型

当$R^2 < 0$ 数据可能不存在线性关系

# 多元线性回归



